# System-wide configuration for LLMaestro

# Global LLM settings
llm:
  # Global rate limiting and quotas
  global_rate_limits:
    requests_per_minute: 5000
    tokens_per_minute: 500000
  max_parallel_requests: 10
  max_retries: 3
  retry_delay: 1.0

  # Default timeouts
  default_request_timeout: 30.0
  default_stream_timeout: 60.0

  # Cache settings
  enable_response_cache: true
  cache_ttl: 3600  # 1 hour

  # Logging and monitoring
  log_level: "INFO"
  enable_telemetry: false

# Default agent configurations
agents:
  max_agents: 10
  default_agent_type: "general"
  agent_types:
    general:
      provider: "anthropic"
      model: "claude-3-sonnet-20240229"
      max_tokens: 8192
      temperature: 0.7
      description: "Default general-purpose agent"

    fast:
      provider: "anthropic"
      model: "claude-3-haiku-20240229"
      max_tokens: 4096
      temperature: 0.7
      description: "Fast, lightweight agent for simple tasks"

    specialist:
      provider: "anthropic"
      model: "claude-3-opus-20240229"
      max_tokens: 16384
      temperature: 0.7
      description: "Specialist agent for complex tasks"

# Storage configuration
storage:
  path: "chain_storage"
  format: "json"
  max_size_mb: 1000
  cleanup_interval: 86400  # 24 hours
  retention_days: 30

# Visualization settings
visualization:
  enabled: true
  host: "localhost"
  port: 8501
  debug: false
  theme: "light"

# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "llmaestro.log"
  max_size_mb: 100
  backup_count: 5
