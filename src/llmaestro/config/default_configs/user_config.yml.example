# User-specific configuration for LLMaestro
# Copy this file to user_config.yml and update with your settings

# API keys for different providers
# These can also be set via environment variables: {PROVIDER}_API_KEY
api_keys:
  openai: "sk-..."  # Your OpenAI API key
  anthropic: "sk-ant-..."  # Your Anthropic API key
  cohere: "..."  # Your Cohere API key
  mistral: "..."  # Your Mistral API key

# Default model configuration
default_model:
  provider: "anthropic"
  name: "claude-3-sonnet-20240229"
  settings:
    max_tokens: 8192
    temperature: 0.7
    top_p: 1.0

# Agent pool configuration
# Override system defaults here if needed
agents:
  max_agents: 10
  default_agent_type: "general"
  agent_types:
    general:
      provider: "anthropic"
      model: "claude-3-sonnet-20240229"
      max_tokens: 8192
      temperature: 0.7
      description: "Default general-purpose agent"
    
    fast:
      provider: "anthropic"
      model: "claude-3-haiku-20240229"
      max_tokens: 4096
      temperature: 0.7
      description: "Fast, lightweight agent for simple tasks"
    
    specialist:
      provider: "anthropic"
      model: "claude-3-opus-20240229"
      max_tokens: 16384
      temperature: 0.7
      description: "Specialist agent for complex tasks"

# Storage configuration
storage:
  path: "chain_storage"  # Relative to workspace or absolute path
  format: "json"  # json or yaml

# Visualization preferences
visualization:
  enabled: true
  host: "localhost"
  port: 8501
  debug: false

# Logging preferences
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL 